# config/default_config.yaml
data:
  raw_documents_path: "data/raw_documents"
  processed_path: "data/processed" 
  datasets_path: "data/datasets"

models:
  discriminator_path: "models/fact_discriminator"
  generator_sft_path: "models/generator_sft"
  generator_rl_path: "models/generator_rl"
  base_model: "TinyLlama/TinyLlama-1.1B-Chat-v1.0"

training:
  batch_size: 2
  learning_rate: 2e-5
  num_epochs: 3

inference:
  max_length: 100
  temperature: 0.7