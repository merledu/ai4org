# Training / run configuration
seed: 42
device: auto      # "auto", "cpu", or "cuda"
gen_model: "distilbert/distilgpt2"
disc_model: "distilbert-base-uncased"

# SFT / discriminator / RL hyperparams (small defaults for CPU)
sft_epochs: 2
sft_batch: 1
sft_lr: 5e-6

disc_epochs: 3
disc_batch: 8
disc_lr: 2e-5

rl_epochs: 2
mc_rollouts: 3
gen_batch_size: 1
gen_lr: 1e-5
max_gen_tokens: 64
min_gen_tokens: 5
top_k: 3

# Reward weights
fact_weight: 0.8
style_weight: 0.15
safety_weight: 0.05
hard_penalty_if_fact_lt: 0.4

save_dir: "models"
output_dir: "outputs"

# quick-run guard (when true, apply CPU-friendly reductions)
quick_run: true
